# Copy this file to .env and modify the values according to your environment

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Model Configuration
DEFAULT_MODEL=llama3.2:3b
DEFAULT_TEMPERATURE=0.5
DEFAULT_TIMEOUT=30

# Application Security (IMPORTANT: Change for production)
DEBUG=False
ALLOWED_HOSTS=localhost,127.0.0.1
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# Server Configuration
GUNICORN_PORT=8000
GUNICORN_WORKERS=1

# Python Virtual Environment Path
PYTHON_VENV=.pyenv

# Frontend Configuration
VITE_OLLAMA_SERVER_BASE_URL=http://localhost